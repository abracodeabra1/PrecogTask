{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lekSnYFDJDOe",
        "outputId": "6b8c585b-4d65-4a88-c0d0-6288671684af"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting en-core-web-lg==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.7.1) (3.7.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.16.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.1.5)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.7.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        }
      ],
      "source": [
        "!pip -q install fasttext\n",
        "# !wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M-subword.vec.zip\n",
        "import nltk\n",
        "import string\n",
        "import os\n",
        "import numpy as np\n",
        "import fasttext\n",
        "nltk.download('brown')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import brown\n",
        "from nltk.corpus import wordnet\n",
        "import io\n",
        "import spacy\n",
        "!python -m spacy download en_core_web_lg\n",
        "nlp = spacy.load(\"en_core_web_lg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PKozgHUpJLM-"
      },
      "outputs": [],
      "source": [
        "def readingfile(filename):\n",
        "    with open(filename, 'r') as file:\n",
        "        next(file)\n",
        "        lines = file.readlines()\n",
        "        # word1_list = []\n",
        "        # word2_list = []\n",
        "        # simlex999_list = []\n",
        "        scores = {}\n",
        "\n",
        "        for line in lines:\n",
        "            data = line.strip().split('\\t')\n",
        "            # print(data)\n",
        "\n",
        "            word1 = data[0]\n",
        "            word2 = data[1]\n",
        "            simlex999 = float(data[3])\n",
        "\n",
        "            # word1_list.append(word1)\n",
        "            # word2_list.append(word2)\n",
        "            key = word1 + \" \" + word2\n",
        "            scores[key] = simlex999\n",
        "            # simlex999_list.append(simlex999)\n",
        "    # for key in scores.keys():\n",
        "    #     print(key, scores[key])\n",
        "    return scores\n",
        "\n",
        "def find_syns(word):\n",
        "    syn = []\n",
        "    ant = []\n",
        "    for synset in wordnet.synsets(word):\n",
        "        for lemma in synset.lemmas():\n",
        "            if '_' not in lemma.name():\n",
        "                syn.append(lemma.name())\n",
        "            if lemma.antonyms():\n",
        "                if '_' not in lemma.antonyms()[0].name():\n",
        "                    ant.append(lemma.antonyms()[0].name())\n",
        "\n",
        "    syn = set(syn)\n",
        "    ant = set(ant)\n",
        "    return syn, ant\n",
        "\n",
        "def cosine_similarity(array1, array2):\n",
        "    dot_product = np.dot(array1, array2)\n",
        "    norm_array1 = np.linalg.norm(array1)\n",
        "    norm_array2 = np.linalg.norm(array2)\n",
        "    cosine_similarity = dot_product / (norm_array1 * norm_array2)\n",
        "    return cosine_similarity\n",
        "\n",
        "\n",
        "def load_vectors(fname):\n",
        "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
        "    n, d = map(int, fin.readline().split())\n",
        "    data = {}\n",
        "    for line in fin:\n",
        "        tokens = line.rstrip().split(' ')\n",
        "        data[tokens[0]] = map(float, tokens[1:])\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adjhWTgWJLWZ",
        "outputId": "467a59b8-b778-4607-e40c-8cbf21d726d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.649\n",
            "336 312 132 219\n"
          ]
        }
      ],
      "source": [
        "test_scores = readingfile(\"SimLex-999.txt\")\n",
        "\n",
        "tp, tn, fp, fn = 0, 0, 0, 0\n",
        "decision_bound = 4\n",
        "count = 0\n",
        "boundary_score = 0.5\n",
        "\n",
        "# if os.path.exists(\"model.bin\"):\n",
        "#     model = fasttext.load_model(\"model.bin\")\n",
        "# else:\n",
        "#     model = fasttext.train_unsupervised(\"data.txt\")\n",
        "#     model.save_model(\"model.bin\")\n",
        "\n",
        "# filename = \"wiki-news-300d-1M-subword.vec\"\n",
        "\n",
        "# data = load_vectors(filename)\n",
        "# print(data)\n",
        "# oldie = model.get_word_vector(\"Chomsky\")\n",
        "# age = model.get_word_vector(\"Antarctica\")\n",
        "\n",
        "# print(cosine_similarity(oldie, age))\n",
        "\n",
        "for key in test_scores.keys():\n",
        "    word1, word2 = key.split()\n",
        "    score = test_scores[key]\n",
        "    syn1, ant1 = find_syns(word1)\n",
        "    syn2, ant2 = find_syns(word2)\n",
        "    if (word1 in ant2) or (word2 in ant1):\n",
        "        if (score < decision_bound):\n",
        "            tn += 1\n",
        "        else:\n",
        "            fn += 1\n",
        "        continue\n",
        "            # print(word1, word2, \"fn\")\n",
        "    elif (word1 in syn2) or (word2 in syn1):\n",
        "        if (score >= decision_bound):\n",
        "            tp += 1\n",
        "        else:\n",
        "            fp += 1\n",
        "        continue\n",
        "            # print(word1, word2, \"fp\")\n",
        "    else:\n",
        "        doc1 = nlp(word1)\n",
        "        doc2 = nlp(word2)\n",
        "        sim_score = doc1.similarity(doc2)\n",
        "        if (sim_score > boundary_score):\n",
        "            if (score > decision_bound):\n",
        "                tp += 1\n",
        "            else:\n",
        "                fp += 1\n",
        "        else:\n",
        "            if (score > decision_bound):\n",
        "                fn += 1\n",
        "            else:\n",
        "                tn += 1\n",
        "\n",
        "\n",
        "        # print(word1, word2, sim_score)\n",
        "\n",
        "\n",
        "\n",
        "if (tp + tn + fp + fn > 0):\n",
        "    print(round((tp + tn)/(fp + fn + tp + tn), 3))\n",
        "    # print(tp, tn, fp, fn)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
